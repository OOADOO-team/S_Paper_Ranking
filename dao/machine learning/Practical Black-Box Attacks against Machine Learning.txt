name: Practical Black-Box Attacks against Machine Learningurl: http://arxiv.org/abs/1602.02697public_in: Noneauthors: Papernot, Nicolas,McDaniel, Patrick,Goodfellow, Ian,abstract: Abstract:  Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.citations_number: 173Citation: On Detecting Adversarial Perturbations "Metzen, Jan Hendrik" "Genewein, Tim" "Fischer, Volker" "Bischoff, Bastian" http://xueshu.baidu.com/usercenter/paper/show?paperid=e6851206c95b0f6b6b5f279bd99cb8d9On the (Statistical) Detection of Adversarial Examples "Grosse, Kathrin" "Manoharan, Praveen" "Papernot, Nicolas" "Backes, Michael" "McDaniel, Patrick" http://xueshu.baidu.com/usercenter/paper/show?paperid=6dc3be80bf7ad7640019118d927a4943Parseval Networks: Improving Robustness to Adversarial Examples "Cisse, Moustapha" "Bojanowski, Piotr" "Grave, Edouard" "Dauphin, Yann" "Usunier, Nicolas" http://xueshu.baidu.com/usercenter/paper/show?paperid=68be5453a5e2421fdbf4dd295c8a1cf2MagNet: A Two-Pronged Defense against Adversarial Examples "Meng, Dongyu" "Chen, Hao" http://xueshu.baidu.com/usercenter/paper/show?paperid=a9c1976d336d4ebd7050b067d280e7caZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models "Chen, Pin-Yu" "Zhang, Huan" "Sharma, Yash" "Yi, Jinfeng" "Hsieh, Cho-Jui" http://xueshu.baidu.com/usercenter/paper/show?paperid=36e1eee6d21167da0627121dce2178cdFeature Squeezing: Detecting Adversarial Examples in Deep Neural Networks "Xu, Weilin" "Evans, David" "Qi, Yanjun" http://xueshu.baidu.com/usercenter/paper/show?paperid=c17d61617d6db7ea3a9e5f59dff2c3e5Adversarial Attacks on Neural Network Policies "Sandy Huang" "Nicolas Papernot" "Ian Goodfellow" "Yan Duan" "Pieter Abbeel" http://xueshu.baidu.com/usercenter/paper/show?paperid=bdb5e9745fa3d22e7b88d98dad28bd3cOne pixel attack for fooling deep neural networks "Su, Jiawei" "Vargas, Danilo Vasconcellos" "Kouichi, Sakurai" http://xueshu.baidu.com/usercenter/paper/show?paperid=e9259817e2237e24ba9e67e44dc53518Adversarial Examples for Semantic Segmentation and Object Detection "Cihang Xie" "Jianyu Wang" "Zhishuai Zhang" "Yuyin Zhou" "Lingxi Xie" "Alan Yuille" http://xueshu.baidu.com/usercenter/paper/show?paperid=6223015abea2a03a1127d3808eab43e1The Space of Transferable Adversarial Examples "Tramèr, Florian" "Papernot, Nicolas" "Goodfellow, Ian" "Boneh, Dan" "McDaniel, Patrick" http://xueshu.baidu.com/usercenter/paper/show?paperid=226f9ee0829cfe1f511801ec80050f12References: Random sampling with a reservoir "Jeffrey S. Vitter" http://xueshu.baidu.com/usercenter/paper/show?paperid=29f56f54604428abb7181c252ca41ffeIntriguing properties of neural networks "Szegedy, Christian" "Zaremba, Wojciech" "Sutskever, Ilya" "Bruna, Joan" "Erhan, Dumitru" "Goodfellow, Ian" "Fergus, Rob" http://xueshu.baidu.com/usercenter/paper/show?paperid=07a58bbfb25ff2a5b053814d1ae5448dMan vs. computer: benchmarking machine learning algorithms for traffic sign recognition "Stallkamp J" "Schlipsing M" "Salmen J" "Igel C" http://xueshu.baidu.com/usercenter/paper/show?paperid=16adc7a464bd7bb75a705daad9efa95fThe Limitations of Deep Learning in Adversarial Settings "Nicolas Papernot" "Patrick McDaniel" "Somesh Jha" "Matt Fredrikson" "Z. Berkay Celik" "Ananthram Swami" http://xueshu.baidu.com/usercenter/paper/show?paperid=59d5f27d294c6fe95b89ffa3e3360cffDistillation as a Defense to Adversarial Perturbations Against Deep Neural Networks "Nicolas Papernot" "Patrick McDaniel" "Xi Wu" "Somesh Jha" "Ananthram Swami" http://xueshu.baidu.com/usercenter/paper/show?paperid=0a1590101077b077ffd35f1d3900c490Adversarial examples in the physical world "Kurakin, Alexey" "Goodfellow, Ian" "Bengio, Samy" http://xueshu.baidu.com/usercenter/paper/show?paperid=5052ea7719c18f06d075c1719bf4fc5bAdversarial Machine Learning "J.D. Tygar" http://xueshu.baidu.com/usercenter/paper/show?paperid=be499eb0e9cf41baf50237a81d518a5aAdversarial Machine Learning "J. D. Tygar" http://xueshu.baidu.com/usercenter/paper/show?paperid=9d0357a1895db1d816db0a40017ba1c3Evasion Attacks against Machine Learning at Test Time "Battista Biggio" "Igino Corona" "Davide Maiorca" "Blaine Nelson" "Nedim Šrndić" "Pavel Laskov" "Giorgio Giacinto" "Fabio Roli" http://xueshu.baidu.com/usercenter/paper/show?paperid=d11234834400d093a565a674f7ee01dcEvasion attacks against machine learning at test time. "Biggio, Battista" "Corona, Igino" "Maiorca, Davide" "Nelson, Blaine" "Šrndić, Nedim" "Laskov, Pavel" "Giacinto, Giorgio" "Roli, Fabio" http://xueshu.baidu.com/usercenter/paper/show?paperid=4dd9c8e3302e0d29d9d534060d3007e8Practical Evasion of a Learning-Based Classifier: A Case Study "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Nedim rndic" "Pavel Laskov" http://xueshu.baidu.com/usercenter/paper/show?paperid=74798419864ce918eaf84e8499f6bb34Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Mahmood Sharif" "Sruti Bhagavatula" "Lujo Bauer" "Michael K. Reiter" http://xueshu.baidu.com/usercenter/paper/show?paperid=1e95745f13d36955ea1683ede8b60f61Stealing Machine Learning Models via Prediction APIs "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Florian Tramèr" "Fan Zhang" "Ari Juels" "Michael K. Reiter" "Thomas Ristenpart" http://xueshu.baidu.com/usercenter/paper/show?paperid=99d5d111420bf4d36531053c652218d1The Limitations of Deep Learning in Adversarial Settings "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Nicolas Papernot" "Patrick McDaniel" "Somesh Jha" "Matt Fredrikson" "Z. Berkay Celik" "Ananthram Swami" http://xueshu.baidu.com/usercenter/paper/show?paperid=b7b5b2f962a5405e484e6c69ba2067e5Adversarial Machine Learning "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Tygar, J.D" http://xueshu.baidu.com/usercenter/paper/show?paperid=3480211fd02dc9e58b632511c5906298Practical Evasion of a Learning-Based Classifier: A Case Study "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "全网免费下载" "Rndic, N" "Laskov, P" http://xueshu.baidu.com/usercenter/paper/show?paperid=a53fda43328449de77e7ab46388a2382