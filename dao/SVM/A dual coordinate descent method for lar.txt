name: A dual coordinate descent method for large-scale linear SVMurl: http://www.researchgate.net/publication/215601307_A_dual_coordinate_descent_method_for_large-scale_linear_SVMpublic_in: ResearchGateauthors: ChoJui Hsieh,KaiWei Chang,ChihJen Lin,abstract: In many applications, data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1-and L2-loss functions. The proposed method is simple and reaches an &amp;#949;-accurate solution in O(log(1/&amp;#949;)) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos, TRON, SVMperf, and a recent primal coordinate descent implementation.citations_number: 617Citation: LIBLINEAR: A Library for Large Linear Classification http://xueshu.baidu.com/usercenter/paper/show?paperid=a3fe9da36ff3056948f663b10aeae1acPegasos: primal estimated sub-gradient solver for SVM http://xueshu.baidu.com/usercenter/paper/show?paperid=ae6c072ade580521f7579e080925188cA dual coordinate descent method for large-scale linear SVM http://xueshu.baidu.com/usercenter/paper/show?paperid=54dfcb422ec8bdb4e12fd06ce1a80a70Foundations of Machine Learning http://xueshu.baidu.com/usercenter/paper/show?paperid=819210f266a230533dd4614e1f5fe1bcAccelerating stochastic gradient descent using predictive variance reduction http://xueshu.baidu.com/usercenter/paper/show?paperid=cc654c840481c7bcd835cc2ef7d0d572Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization http://xueshu.baidu.com/usercenter/paper/show?paperid=68f255778794851c112237f5da7b5843Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function http://xueshu.baidu.com/usercenter/paper/show?paperid=259970881ab03e001104503a718750f8Bundle Methods for Regularized Risk Minimization http://xueshu.baidu.com/usercenter/paper/show?paperid=57fa0049b0c07effb4183dfe40aea40dBatch tuning strategies for statistical machine translation http://xueshu.baidu.com/usercenter/paper/show?paperid=7ec3ef011173d6583d3b2b56adb9d611Iteration Complexity of Randomized Block-Coordinate Descent Methods for Minimizing a Composite Function http://xueshu.baidu.com/usercenter/paper/show?paperid=734947a57fb6b7c6fa2a34c8743b0a4cReferences: Pegasos: Primal Estimated sub-GrAdient SOlver for SVM http://xueshu.baidu.com/usercenter/paper/show?paperid=d19c179365153d7743cf5aab07472191Ultraconservative Online Algorithms for Multiclass Problems http://xueshu.baidu.com/usercenter/paper/show?paperid=f89c2f87f8e01e5a87dc218555c13c5fSuccessive overrelaxation for support vector machines. http://xueshu.baidu.com/usercenter/paper/show?paperid=c986a2e5dbef193c7cfbc659ee17a867Ultraconservative online algorithms for multiclass problems http://xueshu.baidu.com/usercenter/paper/show?paperid=d4ced7b042508e53b21de3399b6a5938A dual coordinate descent method for large-scale linear SVM http://xueshu.baidu.com/usercenter/paper/show?paperid=54dfcb422ec8bdb4e12fd06ce1a80a70The Kernel-Adatron Algorithm: A Fast and Simple Learning Procedure for Support Vector Machines http://xueshu.baidu.com/usercenter/paper/show?paperid=fcef67189e1befbb9bdbe4df36b5b48bSolving large scale linear prediction problems using stochastic gradient descent algorithms http://xueshu.baidu.com/usercenter/paper/show?paperid=1a5ea83cca5a2b2804e1fb583d70df08On the convergence of the coordinate descent method for convex differentiable minimization http://xueshu.baidu.com/usercenter/paper/show?paperid=aaafedaa91fc64a473c98a78ef6f973eA Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs http://xueshu.baidu.com/usercenter/paper/show?paperid=9c7c972157a68994d690d056ae934d2bTrust region Newton methods for large-scale logistic regression http://xueshu.baidu.com/usercenter/paper/show?paperid=59e9910637ef05fa78acf4e4a48d1b55Trust Region Newton Method for Logistic Regression http://xueshu.baidu.com/usercenter/paper/show?paperid=dfd823aac4dc2a19ea6c77ecb04a3992Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines- http://xueshu.baidu.com/usercenter/paper/show?paperid=1ba2a679a2a3a6556d3c1a8f1da51fb1Exponentiated gradient algorithms for conditional random fields and maxmargin Markov networks http://xueshu.baidu.com/usercenter/paper/show?paperid=677ea3a48a82875075dc2ab414cc652dSolving multiclass support vector machines with LaRank http://xueshu.baidu.com/usercenter/paper/show?paperid=82c00d7d5f3ac60f90ed8d53c712b092Bundle methods for machine learning http://xueshu.baidu.com/usercenter/paper/show?paperid=80b54643e2fde3f0804bb42b8cb519a0Decomposition Methods for Linear Support Vector Machines http://xueshu.baidu.com/usercenter/paper/show?paperid=590e2edbc6dd31980b2f8a7554c10c12Decomposition methods for linear support vector machines http://xueshu.baidu.com/usercenter/paper/show?paperid=050e8b9af989e4158068806998566803Successive overrelaxation for support vector machines http://xueshu.baidu.com/usercenter/paper/show?paperid=4cf050f3218bdf5b15f8eacd0a27e6b2