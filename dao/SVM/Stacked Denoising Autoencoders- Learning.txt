name: Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterionurl: http://www.ams.org/mathscinet-getitem?mr=2756188public_in: AMSauthors: Pascal Vincent,Hugo Larochelle,Isabelle Lajoie,abstract: Whereas theoretical work suggests that deep ar- chitectures might be more efficient at represent- ing highly-varying functions, training deep ar- chitectures was unsuccessful until the recent ad- vent of algorithms based on unsupervised pre- training. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem....   [Show full abstract]citations_number: 1591Citation: Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups http://xueshu.baidu.com/usercenter/paper/show?paperid=c83ac93a26e3c2d52605c0cadbbf44afRepresentation Learning: A Review and New Perspectives http://xueshu.baidu.com/usercenter/paper/show?paperid=14655222a985bcb548e882bcd92e006bPractical Recommendations for Gradient-Based Training of Deep Architectures http://xueshu.baidu.com/usercenter/paper/show?paperid=fb55b8f514538dfa823685278d935e49Practical Recommendations for Gradient-Based Training of Deep Architectures http://xueshu.baidu.com/usercenter/paper/show?paperid=c8bfce54e0e73a759dd756b8b6d16497Algorithms for hyper-parameter optimization http://xueshu.baidu.com/usercenter/paper/show?paperid=f8c05222204f399bcd5ada0551641cfbA Method of Automated Nonparametric Content Analysis for Social Science http://xueshu.baidu.com/usercenter/paper/show?paperid=f8d36b11fa659b8383f1f33a5d76a5bcUnsupervised Feature Learning and Deep Learning: A Review and New Perspectives http://xueshu.baidu.com/usercenter/paper/show?paperid=efaf1c1a9979b9ca7ef13640afbf28f6On the expressive power of deep architectures. http://xueshu.baidu.com/usercenter/paper/show?paperid=0e0a4d5d7a3eb132d4989ca390a34564On the Expressive Power of Deep Architectures http://xueshu.baidu.com/usercenter/paper/show?paperid=ebfda71b13ff4c88308fad46cd492385Collaborative Deep Learning for Recommender Systems http://xueshu.baidu.com/usercenter/paper/show?paperid=ca73b49b0c772b70c2be12eb1de04779References: Greedy layer-wise training of deep networks http://xueshu.baidu.com/usercenter/paper/show?paperid=3b1296a1a99139410510da5ec2fab36cReceptive fields of single neurones in the cat's striate cortex http://xueshu.baidu.com/usercenter/paper/show?paperid=d385bafcb70786bc2f91fcfde1da9999Greedy Layer-Wise Training of Deep Networks http://xueshu.baidu.com/usercenter/paper/show?paperid=644707fe6b1c5338218378a780ff302fInformation Processing in Dynamical Systems: Foundations of Harmony Theory http://xueshu.baidu.com/usercenter/paper/show?paperid=66b51e56e914abb0671c0dba9fe63fdfRepublication of The Journal of Physiology (1959) 148, 574-591: Receptive fields of single neurones in the cat's striate cortex. 1959 http://xueshu.baidu.com/usercenter/paper/show?paperid=ef80885f056123d7605ba213ce0ce5b3Why Does Unsupervised Pre-training Help Deep Learning? http://xueshu.baidu.com/usercenter/paper/show?paperid=87ed69dbe5329327afd778ff4b08844dEfficient Learning of Sparse Representations with an Energy-Based Model http://xueshu.baidu.com/usercenter/paper/show?paperid=035040c753ddf09528a2cb02d2a1cc6aDependency networks for inference, collaborative filtering, and data visualization http://xueshu.baidu.com/usercenter/paper/show?paperid=6691340819493abaaa0a05c0ed7ccb69Sparse Deep Belief Net Model for Visual Area V2 http://xueshu.baidu.com/usercenter/paper/show?paperid=557f0ea7dbb984e7cd4f4db012e9e678Almost optimal lower bounds for small depth circuits http://xueshu.baidu.com/usercenter/paper/show?paperid=2d38d5f4aeecc708949459500c45f85eCreating artificial neural networks that generalize. http://xueshu.baidu.com/usercenter/paper/show?paperid=cefb89e38ae506975120c353d5277bcfTraining with Noise is Equivalent to Tikhonov Regularization http://xueshu.baidu.com/usercenter/paper/show?paperid=42b3009a52dc78acb8d559c35eb99c9cSparse feature learning for deep belief networks http://xueshu.baidu.com/usercenter/paper/show?paperid=675c2bec4529b5a9b8f72ef44a9c1f20An empirical evaluation of deep architectures on problems with many factors of variation http://xueshu.baidu.com/usercenter/paper/show?paperid=d2e5d69632f7b5066c35877b1053f146Exploring Strategies for Training Deep Neural Networks. http://xueshu.baidu.com/usercenter/paper/show?paperid=cc41ea6fcfca431f887de06c013b6caaDocument image defect models http://xueshu.baidu.com/usercenter/paper/show?paperid=6c700c81c17c745d0c90e57c4502b5fdUsing additive noise in back-propagation training http://xueshu.baidu.com/usercenter/paper/show?paperid=fea4e89121eb81d9741b6e761cc7803aIncorporating invariances in support vector learning machines http://xueshu.baidu.com/usercenter/paper/show?paperid=6bce1c5a93e820974a7a0d4bc5957b49Incorporating invariances in support vector learning machines http://xueshu.baidu.com/usercenter/paper/show?paperid=f975add733c5aaf7d968f2b7c4bd91aaIncorporating invariances in support vector learning machines http://xueshu.baidu.com/usercenter/paper/show?paperid=9a64ee3560cd7c355a20f95035b084fdDocument Image Defect Models http://xueshu.baidu.com/usercenter/paper/show?paperid=ab241a6c9c57a1247e664d44b0c25419On the power of small-depth threshold circuits http://xueshu.baidu.com/usercenter/paper/show?paperid=a7ef864eafb52dc28899d084f684f85eTangent prop: a formalism for specifying selected invariances in an adaptive network http://xueshu.baidu.com/usercenter/paper/show?paperid=d0a0b0c7f61ad96de80c33c5c7bc9080Recognition and Structure from One 2D Model View: Observations on Prototypes, Object Classes and Symmetries http://xueshu.baidu.com/usercenter/paper/show?paperid=8252fb9b46e6dedb453acb0773cef6c7On the power of small-depth threshold circuits http://xueshu.baidu.com/usercenter/paper/show?paperid=3303033b8b97f2b0af44aacce0bb9078An application of the principle of maximum information preservation to linear systems http://xueshu.baidu.com/usercenter/paper/show?paperid=95a9d3b2869b090dc6308cd567d64cd8Natural image denoising with convolutional networks http://xueshu.baidu.com/usercenter/paper/show?paperid=6f4021777035a10a9500676bab148d1dJustifying and generalizing contrastive divergence http://xueshu.baidu.com/usercenter/paper/show?paperid=9c98340f15b348216be71bb74f8cdadeNoise injection: theoretical prospects http://xueshu.baidu.com/usercenter/paper/show?paperid=635c3793c18c4643b527df8c9ddc948aReal-Time Control of a Tokamak Plasma Using Neural Networks http://xueshu.baidu.com/usercenter/paper/show?paperid=8ca91845328ef77748921fc3e4d63267Many-layered learning. http://xueshu.baidu.com/usercenter/paper/show?paperid=69888917aad044c02f561c8455e74788Factors influencing learning by backpropagation http://xueshu.baidu.com/usercenter/paper/show?paperid=736be74981f9c1692a31628f223a49d2Efficient Learning of Sparse Representations with an Energy-Based Model http://xueshu.baidu.com/usercenter/paper/show?paperid=edab67c76e8ec0e4e23f7f98d122b372