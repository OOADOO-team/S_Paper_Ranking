name: Two view learning: SVM-2K, Theory and Practiceurl: http://www.researchgate.net/publication/221620001_Two_view_learning_SVM-2K_Theory_and_Practicepublic_in: ResearchGateauthors: Jason Farquhar,David Hardoon,Hongying Meng,abstract: Kernel methods make it relatively easy to define complexhigh-dimensional feature spaces. This raises the question of howwe can identify the relevant subspaces for a particular learningtask. When two views of the same phenomenon are available kernelCanonical Correlation Analysis (KCCA) has been shown to be aneffective preprocessing step that can improve the performance ofclassification algorithms such as the Support Vector Machine(SVM). This paper takes this observation to its logical conclusionand proposes a method that combines this two stage learning (KCCAfollowed by SVM) into a single optimisation termed SVM-2K. Wepresent both experimental and theoretical analysis of the approachshowing encouraging results and insights.citations_number: 231Citation: Introduction to Semi-Supervised Learning http://xueshu.baidu.com/usercenter/paper/show?paperid=0aa0c0efc41fbaf9c7d2be4b55198ffcGeneralized Multiview Analysis: A discriminative latent space http://xueshu.baidu.com/usercenter/paper/show?paperid=0f66560551ba5bbfb7240b2bb06d7a09Semi-supervised learning by disagreement http://xueshu.baidu.com/usercenter/paper/show?paperid=106e7fb3b86438a6a50c904632448cbaMultiK-MHKS: A Novel Multiple Kernel Learning Algorithm http://xueshu.baidu.com/usercenter/paper/show?paperid=067c94f1c2306cb0a37de8026287be2eSemi-supervised learning by disagreement http://xueshu.baidu.com/usercenter/paper/show?paperid=3e922960dc9251282e17ee3d908f24b3An RKHS for multi-view learning and manifold co-regularization http://xueshu.baidu.com/usercenter/paper/show?paperid=8638ca62e2dc62502d48667fda968823A survey of multi-view machine learning http://xueshu.baidu.com/usercenter/paper/show?paperid=784c05eebd88988482672d211b47d9bfMultiview Hessian regularization for image annotation http://xueshu.baidu.com/usercenter/paper/show?paperid=179bfeedd1a3a59093740082ab3617daEfficient co-regularised least squares regression http://xueshu.baidu.com/usercenter/paper/show?paperid=fcb96afbad4f1a4ecafbd5c9382983ecMulti-view regression via canonical correlation analysis http://xueshu.baidu.com/usercenter/paper/show?paperid=f8f8759bbf60665a0d5d3ae8c37d16dfReferences: Rademacher and Gaussian Complexities: Risk Bounds and Structural Results http://xueshu.baidu.com/usercenter/paper/show?paperid=c352a110f35625b38ca00b4959a39464Rademacher and Gaussian Complexities: Risk Bounds and Structural Results http://xueshu.baidu.com/usercenter/paper/show?paperid=d6d820d67f782db632bf391699ac887aRademacher and Gaussian Complexities: Risk Bounds and Structural Results http://xueshu.baidu.com/usercenter/paper/show?paperid=875b5f153a75b931415c3f26b308c1f7Kernel PCA and de-noising in feature spaces http://xueshu.baidu.com/usercenter/paper/show?paperid=2f7ccef9f7f7d4d423f61ac2b1e56d9cKernel partial least squares regression in reproducing kernel hilbert space http://xueshu.baidu.com/usercenter/paper/show?paperid=a65b21dac67fe577d738d7a88667607bCanonical Correlation Analysis: An Overview with Application to Learning Methods http://xueshu.baidu.com/usercenter/paper/show?paperid=4caaa40854265bf629e1e4c51ff5d160