name: Poisoning Attacks against Support Vector Machinesurl: http://www.oalib.com/paper/4032943public_in: OALibauthors: Biggio, Battista,Nelson, Blaine,Laskov, Pavel,abstract: Abstract:  We investigate a family of poisoning attacks against Support Vector Machines (SVM). Such attacks inject specially crafted training data that increases the SVM&#039;s test error. Central to the motivation for these attacks is the fact that most learning algorithms assume that their training data comes from a natural or well-behaved distribution. However, this assumption does not generally hold in security-sensitive settings. As we demonstrate, an intelligent adversary can, to some extent, predict the change of the SVM&#039;s decision function due to malicious input and use this ability to construct malicious data. The proposed attack uses a gradient ascent strategy in which the gradient is computed based on properties of the SVM&#039;s optimal solution. This method can be kernelized and enables the attack to be constructed in the input space even for non-linear kernels. We experimentally demonstrate that our gradient ascent procedure reliably identifies good local maxima of the non-convex validation error surface, which significantly increases the classifier&#039;s test error.citations_number: 150Citation: The Limitations of Deep Learning in Adversarial Settings http://xueshu.baidu.com/usercenter/paper/show?paperid=59d5f27d294c6fe95b89ffa3e3360cffDistillation as a Defense to Adversarial Perturbations Against Deep Neural Networks http://xueshu.baidu.com/usercenter/paper/show?paperid=0a1590101077b077ffd35f1d3900c490Evasion Attacks against Machine Learning at Test Time http://xueshu.baidu.com/usercenter/paper/show?paperid=d11234834400d093a565a674f7ee01dcEvasion attacks against machine learning at test time. http://xueshu.baidu.com/usercenter/paper/show?paperid=4dd9c8e3302e0d29d9d534060d3007e8Security Evaluation of Pattern Classifiers under Attack http://xueshu.baidu.com/usercenter/paper/show?paperid=05a0e770f52b7d206c977855ecbca4f5Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples http://xueshu.baidu.com/usercenter/paper/show?paperid=4749d2f354a50c5f2b36c9e03a069ad1Practical Evasion of a Learning-Based Classifier: A Case Study http://xueshu.baidu.com/usercenter/paper/show?paperid=74798419864ce918eaf84e8499f6bb34Stealing Machine Learning Models via Prediction APIs http://xueshu.baidu.com/usercenter/paper/show?paperid=99d5d111420bf4d36531053c652218d1Understanding Black-box Predictions via Influence Functions http://xueshu.baidu.com/usercenter/paper/show?paperid=a979ae445067971000e3958473b37bddVisualizing Object Detection Features http://xueshu.baidu.com/usercenter/paper/show?paperid=f4ca71d5e2597ff8e96db7447ace16a2References: Statistical Fraud Detection: A Review http://xueshu.baidu.com/usercenter/paper/show?paperid=7f41e369677795e2922093b37cf4f365[Statistical Fraud Detection: A Review]: Comment http://xueshu.baidu.com/usercenter/paper/show?paperid=a1bcc5350b6c4dc0d3cce1b20bb638edDetection and analysis of drive-by-download attacks and malicious JavaScript code http://xueshu.baidu.com/usercenter/paper/show?paperid=e768aac5fe0ba4b0ce63d0feec037101Can machine learning be secure? http://xueshu.baidu.com/usercenter/paper/show?paperid=82f35a67d964323606555551f2a2fe70Nightmare at test time:robust learning by feature deletion http://xueshu.baidu.com/usercenter/paper/show?paperid=718151e0825b0ec10d49f7cb9c94b6d3ZOZZLE: fast and precise in-browser JavaScript malware detection http://xueshu.baidu.com/usercenter/paper/show?paperid=7f8bc7fc257eec79b7652f0b9e68b42bThe security of machine learning http://xueshu.baidu.com/usercenter/paper/show?paperid=3647fdc492057d6016200dc93ee96b66Cujo:efficient detection and prevention of drive-by-download attacks http://xueshu.baidu.com/usercenter/paper/show?paperid=49ca3bd1993f1df1b9d5ad22423426b7ANTIDOTE:understanding and defending against poisoning of anomaly detectors http://xueshu.baidu.com/usercenter/paper/show?paperid=088afe9695439aab9becfcf7c805a1daLearning to classify with missing and corrupted features http://xueshu.baidu.com/usercenter/paper/show?paperid=5964c9105bbe9bbae24ac70b99c89deaLearning to classify with missing and corrupted features http://xueshu.baidu.com/usercenter/paper/show?paperid=82af8d5866eec389e8b76094e5377670Exploiting machine learning to subvert your spam filter http://xueshu.baidu.com/usercenter/paper/show?paperid=10c541932fee628b8e763749c419bb05Multiple classifier systems for robust classifier design in adversarial environments http://xueshu.baidu.com/usercenter/paper/show?paperid=df60debe756a35e785e8b0927779fe76A Behavior-Based Approach to Securing Email Systems http://xueshu.baidu.com/usercenter/paper/show?paperid=9fc7b2a6ed1e28531e18d5b0e79800adConvex learning with invariances http://xueshu.baidu.com/usercenter/paper/show?paperid=fb43513947585519bd07a978b87abe1eStatic detection of malicious JavaScript-bearing PDF documents http://xueshu.baidu.com/usercenter/paper/show?paperid=439e3a72bddbef7d45de7305d1f5457cConvex Learning with Invariances http://xueshu.baidu.com/usercenter/paper/show?paperid=8e9748c5b307dfba178f0d8746533cabA Behavior-Based Approach to Securing Email Systems http://xueshu.baidu.com/usercenter/paper/show?paperid=cd0577a6250405e77930028921abbb55